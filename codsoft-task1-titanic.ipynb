{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-09-17T15:33:24.793303Z","iopub.execute_input":"2023-09-17T15:33:24.794044Z","iopub.status.idle":"2023-09-17T15:33:27.635829Z","shell.execute_reply.started":"2023-09-17T15:33:24.793993Z","shell.execute_reply":"2023-09-17T15:33:27.634384Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## â€¢ Funtions","metadata":{}},{"cell_type":"code","source":"def histogram_rep(df,col_name, total_rows,x_label, x_labels, title, figsize):\n    numeric_data = pd.to_numeric(df[col_name], errors='coerce')\n    nan_count = numeric_data.isnull().sum()\n    percentage_non_numeric = (nan_count / total_rows) * 100\n    print(f\"Percentage of non-numerical values in the '{col_name}' column: {percentage_non_numeric:.2f}%\")\n\n    # Get unique values in the 'previous' column\n    unique_values = df[col_name].unique()\n    print(\"Unique values in '{col_name}' column:\")\n    \n    # Calculate the percentage of each unique value\n    percentage_values = []\n    for value in unique_values:\n        count = (df[col_name] == value).sum()\n        percentage = (count / total_rows) * 100\n        percentage_values.append(percentage)\n        print(f\"Value: {value}, Percentage: {percentage:.2f}%\")\n        \n    # Create a histogram\n    plt.figure(figsize=figsize)\n    plt.bar(unique_values, percentage_values)\n    plt.xlabel(x_label)\n    plt.ylabel('Percentage')\n    plt.title(title)\n    plt.xticks(unique_values, x_labels)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:00.248704Z","iopub.execute_input":"2023-09-17T15:34:00.249097Z","iopub.status.idle":"2023-09-17T15:34:00.258062Z","shell.execute_reply.started":"2023-09-17T15:34:00.249066Z","shell.execute_reply":"2023-09-17T15:34:00.256739Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def survival_percentage(data, column_name):\n    unique_values = data[column_name].unique()\n    \n    percentages = {}\n    \n    for value in unique_values:\n        subset = data[data[column_name] == value]\n        survived_count = subset[\"Survived\"].sum()\n        total_count = len(subset)\n        if total_count > 0:\n            percentage = (survived_count / total_count) * 100\n            percentages[value] = percentage\n    \n    return percentages\n","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:07.362196Z","iopub.execute_input":"2023-09-17T15:34:07.362589Z","iopub.status.idle":"2023-09-17T15:34:07.368852Z","shell.execute_reply.started":"2023-09-17T15:34:07.362556Z","shell.execute_reply":"2023-09-17T15:34:07.367590Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def survival_percentage_continuous(data, column_name, num_bins=None, bin_labels=None):\n    if num_bins is None:\n        num_bins = 10  # Default number of bins if not specified\n    \n    if bin_labels is None:\n        bin_labels = [f'Bin {i+1}' for i in range(num_bins)]  # Default bin labels\n    \n    # Create bins for the specified column\n    data['bins'] = pd.cut(data[column_name], bins=num_bins, labels=bin_labels)\n    \n    # Calculate survival percentages for each bin\n    bin_percentages = {}\n    \n    for bin_label in bin_labels:\n        subset = data[data['bins'] == bin_label]\n        survived_count = subset['Survived'].sum()\n        total_count = len(subset)\n        \n        if total_count > 0:\n            percentage = (survived_count / total_count) * 100\n            bin_percentages[bin_label] = percentage\n    \n    # Remove the 'bins' column from the DataFrame (optional)\n    data.drop(columns=['bins'], inplace=True)\n    \n    # Create a bar chart to visualize the survival percentages\n    plt.figure(figsize=(10, 6))\n    plt.bar(bin_percentages.keys(), bin_percentages.values(), color='skyblue')\n    plt.xlabel('Bins')\n    plt.ylabel('Survival Percentage (%)')\n    plt.title(f'Survival Percentage by {column_name}')\n    plt.xticks(rotation=45)\n    plt.grid(axis='y')\n    plt.show()\n    \n    return bin_percentages","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:12.561786Z","iopub.execute_input":"2023-09-17T15:34:12.562947Z","iopub.status.idle":"2023-09-17T15:34:12.572613Z","shell.execute_reply.started":"2023-09-17T15:34:12.562909Z","shell.execute_reply":"2023-09-17T15:34:12.571166Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def draw_pie_chart(percentages):\n    labels = percentages.keys()\n    sizes = list(percentages.values())  # Convert dict_values to a list\n    \n    # Generate a list of shades of blue based on the number of categories\n    num_categories = len(labels)\n    colors = plt.cm.Blues(np.linspace(0.1, 1, num_categories))\n    \n    plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n    plt.pie(sizes, labels=None, colors=colors, autopct=lambda p: f'{p:.1f}%' if p > 0 else '', startangle=140)\n    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n    plt.title('Survival Percentage by Category')\n    \n    # Add custom legend\n    legend_labels = [f'{label} ({sizes[i]:.1f}%)' for i, label in enumerate(labels) if sizes[i] > 0]\n    plt.legend(legend_labels, loc='best')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:17.624917Z","iopub.execute_input":"2023-09-17T15:34:17.625385Z","iopub.status.idle":"2023-09-17T15:34:17.634080Z","shell.execute_reply.started":"2023-09-17T15:34:17.625338Z","shell.execute_reply":"2023-09-17T15:34:17.632595Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def find_between(s, first, last):\n    try:\n        start = s.index( first ) + len( first )\n        end = s.index( last, start )\n        return s[start:end]\n    except ValueError:\n        return \"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.932563Z","iopub.execute_input":"2023-09-06T17:22:22.933778Z","iopub.status.idle":"2023-09-06T17:22:22.948889Z","shell.execute_reply.started":"2023-09-06T17:22:22.933734Z","shell.execute_reply":"2023-09-06T17:22:22.947922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def percent(col_name, total_rows):\n    numeric_data = pd.to_numeric(df[col_name], errors='coerce')\n    nan_count = numeric_data.isnull().sum()\n    percentage_non_numeric = (nan_count / total_rows) * 100\n    print(f\"Percentage of non-numerical values in the '{col_name}' column: {percentage_non_numeric:.2f}%\")\n\n    # Get unique values in the 'previous' column\n    unique_values = df[col_name].unique()\n    print(\"Unique values in '{col_name}' column:\")\n    \n    # Calculate the percentage of each unique value\n    percentage_values = []\n    for value in unique_values:\n        count = (df[col_name] == value).sum()\n        percentage = (count / total_rows) * 100\n        percentage_values.append(percentage)\n        print(f\"Value: {value}, Percentage: {percentage:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.950614Z","iopub.execute_input":"2023-09-06T17:22:22.951076Z","iopub.status.idle":"2023-09-06T17:22:22.962041Z","shell.execute_reply.started":"2023-09-06T17:22:22.951035Z","shell.execute_reply":"2023-09-06T17:22:22.961178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_null_percentage(dataframe):\n    # Calculate the total number of rows in the DataFrame\n    total_rows = len(dataframe)\n    \n    # Calculate the percentage of null values for each feature\n    null_percentage = (dataframe.isnull().sum() / total_rows) * 100\n    \n    return null_percentage","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:22.963526Z","iopub.execute_input":"2023-09-06T17:22:22.964333Z","iopub.status.idle":"2023-09-06T17:22:22.975251Z","shell.execute_reply.started":"2023-09-06T17:22:22.964269Z","shell.execute_reply":"2023-09-06T17:22:22.974024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to extract the ticket category\ndef extract_ticket_category(ticket):\n    if pd.isna(ticket):\n        return None\n    elif ' ' in ticket:\n        return ticket.split(' ')[0]\n    else:\n        return 'Normal'","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:33:49.791725Z","iopub.execute_input":"2023-09-17T15:33:49.792109Z","iopub.status.idle":"2023-09-17T15:33:49.797371Z","shell.execute_reply.started":"2023-09-17T15:33:49.792079Z","shell.execute_reply":"2023-09-17T15:33:49.796179Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def fill_null_with_mode(dataframe, column_name):\n    # Calculate the mode of the column\n    mode_value = dataframe[column_name].mode().iloc[0]\n    \n    # Fill null values with the mode\n    dataframe[column_name].fillna(mode_value, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:33:46.622443Z","iopub.execute_input":"2023-09-17T15:33:46.623305Z","iopub.status.idle":"2023-09-17T15:33:46.628217Z","shell.execute_reply.started":"2023-09-17T15:33:46.623270Z","shell.execute_reply":"2023-09-17T15:33:46.626788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Read the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/test-file/tested.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:33:41.444002Z","iopub.execute_input":"2023-09-17T15:33:41.444405Z","iopub.status.idle":"2023-09-17T15:33:41.454923Z","shell.execute_reply.started":"2023-09-17T15:33:41.444366Z","shell.execute_reply":"2023-09-17T15:33:41.454017Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# â€¢ Data Visualization & Pre-processing","metadata":{}},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:29.260408Z","iopub.execute_input":"2023-09-17T15:34:29.260821Z","iopub.status.idle":"2023-09-17T15:34:29.293531Z","shell.execute_reply.started":"2023-09-17T15:34:29.260787Z","shell.execute_reply":"2023-09-17T15:34:29.292150Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of      PassengerId  Survived  Pclass  \\\n0            892         0       3   \n1            893         1       3   \n2            894         0       2   \n3            895         0       3   \n4            896         1       3   \n..           ...       ...     ...   \n413         1305         0       3   \n414         1306         1       1   \n415         1307         0       3   \n416         1308         0       3   \n417         1309         0       3   \n\n                                             Name     Sex   Age  SibSp  Parch  \\\n0                                Kelly, Mr. James    male  34.5      0      0   \n1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n2                       Myles, Mr. Thomas Francis    male  62.0      0      0   \n3                                Wirz, Mr. Albert    male  27.0      0      0   \n4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n..                                            ...     ...   ...    ...    ...   \n413                            Spector, Mr. Woolf    male   NaN      0      0   \n414                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n415                  Saether, Mr. Simon Sivertsen    male  38.5      0      0   \n416                           Ware, Mr. Frederick    male   NaN      0      0   \n417                      Peter, Master. Michael J    male   NaN      1      1   \n\n                 Ticket      Fare Cabin Embarked  \n0                330911    7.8292   NaN        Q  \n1                363272    7.0000   NaN        S  \n2                240276    9.6875   NaN        Q  \n3                315154    8.6625   NaN        S  \n4               3101298   12.2875   NaN        S  \n..                  ...       ...   ...      ...  \n413           A.5. 3236    8.0500   NaN        S  \n414            PC 17758  108.9000  C105        C  \n415  SOTON/O.Q. 3101262    7.2500   NaN        S  \n416              359309    8.0500   NaN        S  \n417                2668   22.3583   NaN        C  \n\n[418 rows x 12 columns]>\n","output_type":"stream"}]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:33.899144Z","iopub.execute_input":"2023-09-17T15:34:33.899541Z","iopub.status.idle":"2023-09-17T15:34:33.936693Z","shell.execute_reply.started":"2023-09-17T15:34:33.899510Z","shell.execute_reply":"2023-09-17T15:34:33.935887Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   418.000000  418.000000  418.000000  332.000000  418.000000   \nmean   1100.500000    0.363636    2.265550   30.272590    0.447368   \nstd     120.810458    0.481622    0.841838   14.181209    0.896760   \nmin     892.000000    0.000000    1.000000    0.170000    0.000000   \n25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \nmax    1309.000000    1.000000    3.000000   76.000000    8.000000   \n\n            Parch        Fare  \ncount  418.000000  417.000000  \nmean     0.392344   35.627188  \nstd      0.981429   55.907576  \nmin      0.000000    0.000000  \n25%      0.000000    7.895800  \n50%      0.000000   14.454200  \n75%      0.000000   31.500000  \nmax      9.000000  512.329200  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>332.000000</td>\n      <td>418.000000</td>\n      <td>418.000000</td>\n      <td>417.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1100.500000</td>\n      <td>0.363636</td>\n      <td>2.265550</td>\n      <td>30.272590</td>\n      <td>0.447368</td>\n      <td>0.392344</td>\n      <td>35.627188</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>120.810458</td>\n      <td>0.481622</td>\n      <td>0.841838</td>\n      <td>14.181209</td>\n      <td>0.896760</td>\n      <td>0.981429</td>\n      <td>55.907576</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>892.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.170000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>996.250000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.895800</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1100.500000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1204.750000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>39.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1309.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>76.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df.info)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:37.939536Z","iopub.execute_input":"2023-09-17T15:34:37.939923Z","iopub.status.idle":"2023-09-17T15:34:37.954341Z","shell.execute_reply.started":"2023-09-17T15:34:37.939893Z","shell.execute_reply":"2023-09-17T15:34:37.952774Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"<bound method DataFrame.info of      PassengerId  Survived  Pclass  \\\n0            892         0       3   \n1            893         1       3   \n2            894         0       2   \n3            895         0       3   \n4            896         1       3   \n..           ...       ...     ...   \n413         1305         0       3   \n414         1306         1       1   \n415         1307         0       3   \n416         1308         0       3   \n417         1309         0       3   \n\n                                             Name     Sex   Age  SibSp  Parch  \\\n0                                Kelly, Mr. James    male  34.5      0      0   \n1                Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n2                       Myles, Mr. Thomas Francis    male  62.0      0      0   \n3                                Wirz, Mr. Albert    male  27.0      0      0   \n4    Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n..                                            ...     ...   ...    ...    ...   \n413                            Spector, Mr. Woolf    male   NaN      0      0   \n414                  Oliva y Ocana, Dona. Fermina  female  39.0      0      0   \n415                  Saether, Mr. Simon Sivertsen    male  38.5      0      0   \n416                           Ware, Mr. Frederick    male   NaN      0      0   \n417                      Peter, Master. Michael J    male   NaN      1      1   \n\n                 Ticket      Fare Cabin Embarked  \n0                330911    7.8292   NaN        Q  \n1                363272    7.0000   NaN        S  \n2                240276    9.6875   NaN        Q  \n3                315154    8.6625   NaN        S  \n4               3101298   12.2875   NaN        S  \n..                  ...       ...   ...      ...  \n413           A.5. 3236    8.0500   NaN        S  \n414            PC 17758  108.9000  C105        C  \n415  SOTON/O.Q. 3101262    7.2500   NaN        S  \n416              359309    8.0500   NaN        S  \n417                2668   22.3583   NaN        C  \n\n[418 rows x 12 columns]>\n","output_type":"stream"}]},{"cell_type":"code","source":"features = ['Pclass','Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked','Survived']\nnull_percentage = get_null_percentage(df[features])\n\n# Print the null percentage for each feature\nprint(\"Percentage of null values for each feature:\")\nprint(null_percentage,\"%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:35:00.676332Z","iopub.execute_input":"2023-09-17T15:35:00.676782Z","iopub.status.idle":"2023-09-17T15:35:00.706361Z","shell.execute_reply.started":"2023-09-17T15:35:00.676746Z","shell.execute_reply":"2023-09-17T15:35:00.704625Z"},"trusted":true},"execution_count":25,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSibSp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicket\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCabin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmbarked\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m null_percentage \u001b[38;5;241m=\u001b[39m \u001b[43mget_null_percentage\u001b[49m(df[features])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the null percentage for each feature\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage of null values for each feature:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'get_null_percentage' is not defined"],"ename":"NameError","evalue":"name 'get_null_percentage' is not defined","output_type":"error"}]},{"cell_type":"code","source":"df.drop(columns=['Cabin'], inplace=True)\ndf.drop(columns=['Age'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-17T15:34:49.278952Z","iopub.execute_input":"2023-09-17T15:34:49.279881Z","iopub.status.idle":"2023-09-17T15:34:50.813579Z","shell.execute_reply.started":"2023-09-17T15:34:49.279841Z","shell.execute_reply":"2023-09-17T15:34:50.811978Z"},"trusted":true},"execution_count":20,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCabin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5260\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5264\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5265\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n","\u001b[0;31mKeyError\u001b[0m: \"['Cabin'] not found in axis\""],"ename":"KeyError","evalue":"\"['Cabin'] not found in axis\"","output_type":"error"}]},{"cell_type":"code","source":"# Remove 'Cabin' and 'Age' from the features list in one line\nfeatures = [feature for feature in features if feature not in ['Cabin', 'Age']]\n\n# Print the updated features list\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.193239Z","iopub.execute_input":"2023-09-06T17:22:23.193806Z","iopub.status.idle":"2023-09-06T17:22:23.205086Z","shell.execute_reply.started":"2023-09-06T17:22:23.193714Z","shell.execute_reply":"2023-09-06T17:22:23.204193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1) Sex","metadata":{}},{"cell_type":"code","source":"sex_result = survival_percentage(df, \"Sex\")\n\nfor key, value in sex_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(sex_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.206669Z","iopub.execute_input":"2023-09-06T17:22:23.207262Z","iopub.status.idle":"2023-09-06T17:22:23.48672Z","shell.execute_reply.started":"2023-09-06T17:22:23.207231Z","shell.execute_reply":"2023-09-06T17:22:23.48509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thearfore, included","metadata":{}},{"cell_type":"markdown","source":"### 2) Name --> Title","metadata":{}},{"cell_type":"code","source":"df['Title'] = df.apply(lambda row: find_between(row['Name'], \", \", \".\"), axis=1)\nfeatures.append('Title')\ndf.drop(columns=['Name'], inplace=True)\nprint(df['Title'])","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.489175Z","iopub.execute_input":"2023-09-06T17:22:23.490961Z","iopub.status.idle":"2023-09-06T17:22:23.509437Z","shell.execute_reply.started":"2023-09-06T17:22:23.490892Z","shell.execute_reply":"2023-09-06T17:22:23.508025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove 'Name' from the features list\nfeatures.remove('Name')\n\n# Print the updated features list\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.511087Z","iopub.execute_input":"2023-09-06T17:22:23.511566Z","iopub.status.idle":"2023-09-06T17:22:23.525932Z","shell.execute_reply.started":"2023-09-06T17:22:23.511502Z","shell.execute_reply":"2023-09-06T17:22:23.524027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_name = 'Title'\nx_label = 'Title'\ntitle = 'Titles percentages'\nfigsize = (9, 3)\nx_labels = ['Mr', 'Mrs', 'Miss','Master','Ms','Col', 'Rev', 'Dr', 'Dona']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.527549Z","iopub.execute_input":"2023-09-06T17:22:23.527891Z","iopub.status.idle":"2023-09-06T17:22:23.791018Z","shell.execute_reply.started":"2023-09-06T17:22:23.527862Z","shell.execute_reply":"2023-09-06T17:22:23.789784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"title_result = survival_percentage(df, \"Title\")\n\nfor key, value in title_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(title_result)        #others?????","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:23.793391Z","iopub.execute_input":"2023-09-06T17:22:23.794632Z","iopub.status.idle":"2023-09-06T17:22:24.045453Z","shell.execute_reply.started":"2023-09-06T17:22:23.794587Z","shell.execute_reply":"2023-09-06T17:22:24.044181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Same as all 'female' survived in 'Sex' column\n##### So, this column won't be useful in our prediction\n##### Therefore, not included","metadata":{}},{"cell_type":"code","source":"df.drop(columns=['Title'], inplace=True)\nfeatures.remove('Title')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.047205Z","iopub.execute_input":"2023-09-06T17:22:24.048523Z","iopub.status.idle":"2023-09-06T17:22:24.057533Z","shell.execute_reply.started":"2023-09-06T17:22:24.048475Z","shell.execute_reply":"2023-09-06T17:22:24.055853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.060263Z","iopub.execute_input":"2023-09-06T17:22:24.061086Z","iopub.status.idle":"2023-09-06T17:22:24.084534Z","shell.execute_reply.started":"2023-09-06T17:22:24.061037Z","shell.execute_reply":"2023-09-06T17:22:24.083346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3) Embarked","metadata":{}},{"cell_type":"code","source":"col_name = 'Embarked'\nx_label = 'Embarked'\nx_labels = ['Q','S','C']\ntitle = 'Embarked percentage'\nfigsize = (3,3)\n\nhistogram_rep(df,col_name, len(df),x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.08624Z","iopub.execute_input":"2023-09-06T17:22:24.087163Z","iopub.status.idle":"2023-09-06T17:22:24.284022Z","shell.execute_reply.started":"2023-09-06T17:22:24.087092Z","shell.execute_reply":"2023-09-06T17:22:24.282682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked_result = survival_percentage(df, \"Embarked\")\n\nfor key, value in embarked_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.285696Z","iopub.execute_input":"2023-09-06T17:22:24.286128Z","iopub.status.idle":"2023-09-06T17:22:24.519613Z","shell.execute_reply.started":"2023-09-06T17:22:24.286097Z","shell.execute_reply":"2023-09-06T17:22:24.51846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4) Pclass","metadata":{}},{"cell_type":"code","source":"col_name = 'Pclass'\nx_label = 'Pclass'\nx_labels = ['3rd class', '2nd class', '1st class']\ntitle = 'Percentage of Pclass'\nfigsize = (3,4)\n\nhistogram_rep(df,col_name, len(df),x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.521097Z","iopub.execute_input":"2023-09-06T17:22:24.522167Z","iopub.status.idle":"2023-09-06T17:22:24.7148Z","shell.execute_reply.started":"2023-09-06T17:22:24.522128Z","shell.execute_reply":"2023-09-06T17:22:24.713373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embarked_result = survival_percentage(df, \"Pclass\")\n\nfor key, value in embarked_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.723462Z","iopub.execute_input":"2023-09-06T17:22:24.723862Z","iopub.status.idle":"2023-09-06T17:22:24.907192Z","shell.execute_reply.started":"2023-09-06T17:22:24.723832Z","shell.execute_reply":"2023-09-06T17:22:24.906331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5) SibSp","metadata":{}},{"cell_type":"code","source":"col_name = 'SibSp'\nx_label = 'SibSp'\ntitle = 'SibSp percentages'\nfigsize = (4, 3)\nx_labels = ['0','1','2','3','4','5','8']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:24.908274Z","iopub.execute_input":"2023-09-06T17:22:24.908901Z","iopub.status.idle":"2023-09-06T17:22:25.222697Z","shell.execute_reply.started":"2023-09-06T17:22:24.908874Z","shell.execute_reply":"2023-09-06T17:22:25.22139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SibSp_result = survival_percentage(df, \"SibSp\")\n\nfor key, value in SibSp_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(SibSp_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.224076Z","iopub.execute_input":"2023-09-06T17:22:25.224435Z","iopub.status.idle":"2023-09-06T17:22:25.559594Z","shell.execute_reply.started":"2023-09-06T17:22:25.224405Z","shell.execute_reply":"2023-09-06T17:22:25.558387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6) Parch","metadata":{}},{"cell_type":"code","source":"col_name = 'Parch'\nx_label = 'Parch'\ntitle = 'Parch percentages'\nfigsize = (9, 3)\nx_labels = ['0', '1', '3', '2', '4', '6','5','9']      # 8 classes\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.561107Z","iopub.execute_input":"2023-09-06T17:22:25.561793Z","iopub.status.idle":"2023-09-06T17:22:25.859685Z","shell.execute_reply.started":"2023-09-06T17:22:25.561758Z","shell.execute_reply":"2023-09-06T17:22:25.858355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Parch_result = survival_percentage(df, \"Parch\")\n\nfor key, value in Parch_result.items():\n    print(f\"precentage of {key} who survived: {value:.2f}%\")\n    \ndraw_pie_chart(Parch_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:25.861311Z","iopub.execute_input":"2023-09-06T17:22:25.861973Z","iopub.status.idle":"2023-09-06T17:22:26.205148Z","shell.execute_reply.started":"2023-09-06T17:22:25.861938Z","shell.execute_reply":"2023-09-06T17:22:26.204225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7) Ticket","metadata":{}},{"cell_type":"code","source":"# Split the 'Ticket' column and store the first part in 'Ticket_category'\ndf['Ticket_category'] = df['Ticket'].str.split(' ').str[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.206529Z","iopub.execute_input":"2023-09-06T17:22:26.207137Z","iopub.status.idle":"2023-09-06T17:22:26.216571Z","shell.execute_reply.started":"2023-09-06T17:22:26.207099Z","shell.execute_reply":"2023-09-06T17:22:26.215155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_name = 'Ticket'\ndf['Ticket_category'] = df[col_name].apply(extract_ticket_category)\npercent('Ticket_category', len(df))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.217759Z","iopub.execute_input":"2023-09-06T17:22:26.218154Z","iopub.status.idle":"2023-09-06T17:22:26.249791Z","shell.execute_reply.started":"2023-09-06T17:22:26.218122Z","shell.execute_reply":"2023-09-06T17:22:26.248849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Ticket'], inplace=True)\nfeatures.remove('Ticket')\nfeatures.append('Ticket_category')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.251566Z","iopub.execute_input":"2023-09-06T17:22:26.252002Z","iopub.status.idle":"2023-09-06T17:22:26.377726Z","shell.execute_reply.started":"2023-09-06T17:22:26.251973Z","shell.execute_reply":"2023-09-06T17:22:26.376599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the count of each ticket category\nticket_category_counts = df['Ticket_category'].value_counts()\n\n# Extract unique categories and their counts\ncategories = ticket_category_counts.index\ncounts = ticket_category_counts.values\n\n# Create a scatter plot\nplt.figure(figsize=(18, 6))\nplt.scatter(categories, counts, c='blue', marker='o')\nplt.xlabel('Ticket Category')\nplt.ylabel('Count')\nplt.title('Ticket Category Distribution')\nplt.xticks(rotation=45)\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.379592Z","iopub.execute_input":"2023-09-06T17:22:26.380082Z","iopub.status.idle":"2023-09-06T17:22:26.94714Z","shell.execute_reply.started":"2023-09-06T17:22:26.380039Z","shell.execute_reply":"2023-09-06T17:22:26.945403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### So, there is an outlier","metadata":{}},{"cell_type":"code","source":"df.drop(columns=['Ticket_category'], inplace=True)\nfeatures.remove('Ticket_category')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.948951Z","iopub.execute_input":"2023-09-06T17:22:26.949693Z","iopub.status.idle":"2023-09-06T17:22:26.958368Z","shell.execute_reply.started":"2023-09-06T17:22:26.94965Z","shell.execute_reply":"2023-09-06T17:22:26.957205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8) Fare: A numerical variable for the price of the ticket.","metadata":{}},{"cell_type":"code","source":"col_name = 'Fare'\npercent(col_name, len(df))\nsns.kdeplot(data=df['Fare'], color='red')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:26.95985Z","iopub.execute_input":"2023-09-06T17:22:26.961261Z","iopub.status.idle":"2023-09-06T17:22:27.384848Z","shell.execute_reply.started":"2023-09-06T17:22:26.961214Z","shell.execute_reply":"2023-09-06T17:22:27.383578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### â€¢ pre-processing","metadata":{}},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.38635Z","iopub.execute_input":"2023-09-06T17:22:27.386714Z","iopub.status.idle":"2023-09-06T17:22:27.39994Z","shell.execute_reply.started":"2023-09-06T17:22:27.386686Z","shell.execute_reply":"2023-09-06T17:22:27.398347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now, there is non-numerical values\n#####    To remove them we should use linear regression and predict its values from other columns\n##### Or simply drop it","metadata":{}},{"cell_type":"code","source":"# Define the features to use for prediction\n#use_features = ['Pclass', 'Sex_female', 'Sex_male', 'SibSp', 'Parch', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n\n# Filter the DataFrame to only include rows with non-null 'Fare' values\n#df_clean = df.dropna(subset=['Fare'])\n\n# Create the feature matrix X and target variable y\n#X = df_clean[use_features]\n#y = df_clean['Fare']\n\n# Create and fit the linear regression model\n#model = LinearRegression()\n#model.fit(X, y)\n\n# Filter the DataFrame to only include rows with null 'Fare' values\n#null_fare_indices = df[df['Fare'].isnull()].index\n\n# Predict missing 'Fare' values using the model\n#predicted_fares = model.predict(df.loc[null_fare_indices, use_features])\n\n# Fill the null 'Fare' values with the predicted values\n#df.loc[null_fare_indices, 'Fare'] = predicted_fares","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.40189Z","iopub.execute_input":"2023-09-06T17:22:27.402236Z","iopub.status.idle":"2023-09-06T17:22:27.413137Z","shell.execute_reply.started":"2023-09-06T17:22:27.402208Z","shell.execute_reply":"2023-09-06T17:22:27.411464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#col_name = 'Fare'\n#percent(col_name, len(df))\n#sns.kdeplot(data=df['Fare'], color='red')","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.415101Z","iopub.execute_input":"2023-09-06T17:22:27.415656Z","iopub.status.idle":"2023-09-06T17:22:27.431044Z","shell.execute_reply.started":"2023-09-06T17:22:27.415613Z","shell.execute_reply":"2023-09-06T17:22:27.429949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['Fare'], inplace=True)\nfeatures.remove('Fare')\nprint(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.432725Z","iopub.execute_input":"2023-09-06T17:22:27.433085Z","iopub.status.idle":"2023-09-06T17:22:27.449361Z","shell.execute_reply.started":"2023-09-06T17:22:27.433051Z","shell.execute_reply":"2023-09-06T17:22:27.44778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.head)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.450655Z","iopub.execute_input":"2023-09-06T17:22:27.451057Z","iopub.status.idle":"2023-09-06T17:22:27.473296Z","shell.execute_reply.started":"2023-09-06T17:22:27.451025Z","shell.execute_reply":"2023-09-06T17:22:27.471792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9) Embarked: Alphanumerical cabin code.","metadata":{}},{"cell_type":"code","source":"col_name = 'Embarked'\nx_label = 'Embarked'\ntitle = 'Embarked percentages'\nfigsize = (3, 3)\nx_labels = ['Q','S','C']\n\nhistogram_rep(df,col_name, len(df), x_label, x_labels, title, figsize)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.475261Z","iopub.execute_input":"2023-09-06T17:22:27.475805Z","iopub.status.idle":"2023-09-06T17:22:27.683392Z","shell.execute_reply.started":"2023-09-06T17:22:27.475758Z","shell.execute_reply":"2023-09-06T17:22:27.682163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Embarked_result = survival_percentage(df, \"Embarked\")\n\nfor key, value in Embarked_result.items():\n    print(f\"percentage of {key} who survived: {value:.2f}%\")\n\ndraw_pie_chart(Embarked_result)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.684863Z","iopub.execute_input":"2023-09-06T17:22:27.685305Z","iopub.status.idle":"2023-09-06T17:22:27.863239Z","shell.execute_reply.started":"2023-09-06T17:22:27.68525Z","shell.execute_reply":"2023-09-06T17:22:27.861423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.865622Z","iopub.execute_input":"2023-09-06T17:22:27.867482Z","iopub.status.idle":"2023-09-06T17:22:27.877108Z","shell.execute_reply.started":"2023-09-06T17:22:27.86741Z","shell.execute_reply":"2023-09-06T17:22:27.875629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_features = ['Pclass', 'Sex', 'SibSp', 'Parch']\ndf = pd.get_dummies(features)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.87945Z","iopub.execute_input":"2023-09-06T17:22:27.881096Z","iopub.status.idle":"2023-09-06T17:22:27.894231Z","shell.execute_reply.started":"2023-09-06T17:22:27.880962Z","shell.execute_reply":"2023-09-06T17:22:27.892667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.896619Z","iopub.execute_input":"2023-09-06T17:22:27.898355Z","iopub.status.idle":"2023-09-06T17:22:27.924127Z","shell.execute_reply.started":"2023-09-06T17:22:27.898277Z","shell.execute_reply":"2023-09-06T17:22:27.922767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[use_features]\ny = df['Survived']","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.926035Z","iopub.execute_input":"2023-09-06T17:22:27.92668Z","iopub.status.idle":"2023-09-06T17:22:27.941996Z","shell.execute_reply.started":"2023-09-06T17:22:27.926634Z","shell.execute_reply":"2023-09-06T17:22:27.940626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()\ny.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.943408Z","iopub.execute_input":"2023-09-06T17:22:27.943985Z","iopub.status.idle":"2023-09-06T17:22:27.978348Z","shell.execute_reply.started":"2023-09-06T17:22:27.943954Z","shell.execute_reply":"2023-09-06T17:22:27.977408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# â€¢ Divide the data into train and test","metadata":{}},{"cell_type":"code","source":"# Split your data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.979776Z","iopub.execute_input":"2023-09-06T17:22:27.980135Z","iopub.status.idle":"2023-09-06T17:22:27.989368Z","shell.execute_reply.started":"2023-09-06T17:22:27.980104Z","shell.execute_reply":"2023-09-06T17:22:27.988097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split your data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:27.990716Z","iopub.execute_input":"2023-09-06T17:22:27.991094Z","iopub.status.idle":"2023-09-06T17:22:28.010501Z","shell.execute_reply.started":"2023-09-06T17:22:27.991065Z","shell.execute_reply":"2023-09-06T17:22:28.00915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and fit the model\n#model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n#model.fit(X_train, y_train)\n\n# Make predictions on both train and test data\n#train_predictions = model.predict(X_train)\n#test_predictions = model.predict(X_test)\n\n# Calculate train and test accuracy\n#train_accuracy = accuracy_score(y_train, train_predictions)\n#test_accuracy = accuracy_score(y_test, test_predictions)\n\n# Print both train and test accuracy\n#print(f\"Train Accuracy: {train_accuracy:.2%}\")\n#print(f\"Test Accuracy: {test_accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:28.012104Z","iopub.execute_input":"2023-09-06T17:22:28.013408Z","iopub.status.idle":"2023-09-06T17:22:28.026679Z","shell.execute_reply.started":"2023-09-06T17:22:28.013369Z","shell.execute_reply":"2023-09-06T17:22:28.025233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a list of models to try\nmodels = [\n    (\"Random Forest\", RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)),\n    (\"Gradient Boosting\", GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=1)),\n    (\"Logistic Regression\", LogisticRegression(random_state=1))\n]\n\nbest_model = None\nbest_accuracy = 0.0\n\nfor model_name, model in models:\n    print(f\"Training {model_name}...\")\n    \n    train_accuracy_list = []\n    val_accuracy_list = []\n    test_accuracy_list = []\n\n    # Train the model and track accuracy\n    for epoch in range(1, 101):  # You can adjust the number of epochs\n        model.fit(X_train, y_train)\n\n        train_predictions = model.predict(X_train)\n        val_predictions = model.predict(X_val)  # Assuming you have a validation set X_val and y_val\n        test_predictions = model.predict(X_test)\n\n        train_accuracy = accuracy_score(y_train, train_predictions)\n        val_accuracy = accuracy_score(y_val, val_predictions)\n        test_accuracy = accuracy_score(y_test, test_predictions)\n\n        train_accuracy_list.append(train_accuracy)\n        val_accuracy_list.append(val_accuracy)\n        test_accuracy_list.append(test_accuracy)\n\n    # Print both train and test accuracy\n    print(f\"{model_name} Train Accuracy: {train_accuracy:.2%}\")\n    print(f\"{model_name} Validation Accuracy: {val_accuracy:.2%}\")\n    print(f\"{model_name} Test Accuracy: {test_accuracy:.2%}\")\n    print(\"\\n\")\n\n    if val_accuracy > best_accuracy:\n        best_accuracy = val_accuracy\n        best_model = model_name\n        \n# Check if all models have similar accuracy\nsimilar_models = all(val == best_accuracy for val in val_accuracy_list)\nif similar_models:\n    print(\"All models have similar performance.\")\nelse:\n    print(f\"The best model is {best_model} with a validation accuracy of {best_accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:28.028524Z","iopub.execute_input":"2023-09-06T17:22:28.029158Z","iopub.status.idle":"2023-09-06T17:22:59.964804Z","shell.execute_reply.started":"2023-09-06T17:22:28.029123Z","shell.execute_reply":"2023-09-06T17:22:59.963259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting train accuracy vs validation accuracy and train accuracy vs test accuracy\nplt.figure(figsize=(15, 5))\n\n# Train accuracy vs validation accuracy\nplt.subplot(1, 2, 1)\nplt.plot(train_accuracy_list, label='Train Accuracy', c='red')\nplt.plot(val_accuracy_list, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy vs Validation Accuracy')\nplt.legend()\n\n# Train accuracy vs test accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracy_list, label='Train Accuracy', c='red')\nplt.plot(test_accuracy_list, label='Test Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy vs Test Accuracy')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:22:59.966503Z","iopub.execute_input":"2023-09-06T17:22:59.966868Z","iopub.status.idle":"2023-09-06T17:23:00.545331Z","shell.execute_reply.started":"2023-09-06T17:22:59.966839Z","shell.execute_reply":"2023-09-06T17:23:00.544063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model_name, model in models:\n    print(f\"Evaluating {model_name}...\")\n    \n    # Train the model\n    model.fit(X_train, y_train)\n\n    # Make predictions\n    train_predictions = model.predict(X_train)\n    val_predictions = model.predict(X_val)  # Assuming you have a validation set X_val and y_val\n    test_predictions = model.predict(X_test)\n\n    # Calculate confusion matrix and classification report for train data\n    train_cm = confusion_matrix(y_train, train_predictions)\n    train_cr = classification_report(y_train, train_predictions, output_dict=True, zero_division=1)\n    \n    # Calculate confusion matrix and classification report for validation data\n    val_cm = confusion_matrix(y_val, val_predictions)\n    val_cr = classification_report(y_val, val_predictions, output_dict=True, zero_division=1)\n\n    # Calculate confusion matrix and classification report for test data\n    test_cm = confusion_matrix(y_test, test_predictions)\n    test_cr = classification_report(y_test, test_predictions, output_dict=True, zero_division=1)\n    \n    # Display confusion matrix as a heatmap for test data\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(test_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title(f'Confusion Matrix - {model_name} (Test Data)')\n    plt.show()\n\n    # Print classification report for test data\n    print(f\"Classification Report for {model_name} - Test Data:\")\n    print(classification_report(y_test, test_predictions))","metadata":{"execution":{"iopub.status.busy":"2023-09-06T17:23:00.546853Z","iopub.execute_input":"2023-09-06T17:23:00.547189Z","iopub.status.idle":"2023-09-06T17:23:01.940297Z","shell.execute_reply.started":"2023-09-06T17:23:00.547162Z","shell.execute_reply":"2023-09-06T17:23:01.938153Z"},"trusted":true},"execution_count":null,"outputs":[]}]}